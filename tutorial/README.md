# LLM Parallelism 101 w/ TorchTitan: Let's scaple up Llama

- **Executable**: We will learn the parallel mechanism used by Large Laguage models LLMs with runable code, and train a Llama3.1-8B Model, gradually added parallelism technics on top of it.
- **Simple**: We will use TorchTitan and native PyTorch Distributed APIs to implement the parallelism, with minial code change.
- **Extensible**: It could easily extend the parallelism to your own LLM.

**[WIP]** This project is still actively developing.


## Syllabus
- Chapter 0: Transformer, Llama
- Chapter 1: Adding Data Parallelism (DDP, FSDP)
- Chapter 2: Adding Tensor Parallelism (TP)
- Chapter 3: Adding Pipeline Parallelism (PP)
- Chapter 4: Adding ...
